{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d5dcd2b2-4f6f-4dcd-a912-c5f437ede47e",
   "metadata": {},
   "source": [
    "Notebook Overview\n",
    "\n",
    "key objectives:\n",
    "- Loading a pre-trained sentiment analysis model\n",
    "- Validating the model's functionality\n",
    "- Analyzing training performance through visualizations\n",
    "- Generating test cases for model evaluation\n",
    "- Quality assurance through complex review scenarios"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c464c7bf-418c-481a-974c-97387ac17e97",
   "metadata": {},
   "source": [
    "1: Library Imports\n",
    "- Importing core Python libraries for system operations (os, sys)\n",
    "- Setting up deep learning frameworks (tensorflow)\n",
    "- Loading data science tools (numpy, sklearn)\n",
    "- Importing visualization libraries (seaborn, matplotlib)\n",
    "- Including custom project modules for model architecture and analysis\n",
    "- The os.chdir('../') command ensures we're working from the project root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089e0e04-8ba1-4ca7-b79e-ff888b32498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Explicitly set the project root\n",
    "project_root = '/Users/afshinpaydar/Desktop/test/saved_models'\n",
    "# Add to Python path\n",
    "sys.path.insert(0, project_root)\n",
    "os.chdir('../')  # Moving up one directory to the root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f99982f-c792-40a8-a784-e700df541f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import SentimentAnalyzer\n",
    "from config.model_config import Config \n",
    "from models.modelPersistence import ModelPersistence\n",
    "from utils.modelEvaluator import ModelEvaluator"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11b00530-9feb-4380-8ad6-d42f9b2834e2",
   "metadata": {},
   "source": [
    "2. Project Path Setup\n",
    "\n",
    "This cell handles Python path configuration by:\n",
    "- Identifying the project's root directory\n",
    "- Adding it to Python's system path\n",
    "\n",
    "This ensures that Python can find and import custom modules from anywhere in the project structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69aaf66-75bb-4dee-99d2-9673ecb29ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPersistence = ModelPersistence()\n",
    "analyzer = SentimentAnalyzer()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39598a7a-300a-40aa-a650-dc925eb4eb35",
   "metadata": {},
   "source": [
    "3: Model Loading\n",
    "This cell initializes and loads the trained model:\n",
    "- Creates a new SentimentAnalyzer instance\n",
    "- Loads the model weights from the epoch which model is saved \n",
    "- Retrieves both the model and its training history\n",
    "\n",
    "The epoch=10 parameter indicates we're loading the model state after 2 training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9514b3c9-1a46-4704-9d65-b582a9e38d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and setup analyzer\n",
    "analyzer.process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae31a3c-9f2a-4401-80a1-af1d36a1662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary imports at the top of your notebook cell\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from transformers import DistilBertTokenizer\n",
    "from models.sentiment_model import EnhancedDistilBertForSentiment\n",
    "from config.model_config import Config\n",
    "\n",
    "def load_saved_model(epoch, model_dir=None):\n",
    "    \"\"\"\n",
    "    Load a previously saved model with weights and configuration.\n",
    "    Args:\n",
    "        epoch (int): The training epoch to load\n",
    "        model_dir (str): Directory containing saved model files\n",
    "    Returns:\n",
    "        tuple: (loaded_model, training_history)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Handle model directory path\n",
    "        if model_dir is None:\n",
    "            model_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "            \n",
    "        print(f\"Loading model from directory: {model_dir}\")\n",
    "        \n",
    "        # 1. Load model info and configuration\n",
    "        model_info_path = os.path.join(model_dir, f\"model_info_epoch{epoch}.json\")\n",
    "        if not os.path.exists(model_info_path):\n",
    "            raise FileNotFoundError(f\"Model info file not found at: {model_info_path}\")\n",
    "            \n",
    "        with open(model_info_path, 'r') as f:\n",
    "            model_info = json.load(f)\n",
    "            print(\"Loaded model configuration and training history\")\n",
    "            \n",
    "        # 2. Initialize tokenizer\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        print(\"Initialized tokenizer\")\n",
    "            \n",
    "        # 3. Initialize and build model\n",
    "        model = EnhancedDistilBertForSentiment()\n",
    "        \n",
    "        # Build model with dummy input\n",
    "        dummy_input = {\n",
    "            'input_ids': tf.zeros((1, Config.MAX_LENGTH), dtype=tf.int32),\n",
    "            'attention_mask': tf.zeros((1, Config.MAX_LENGTH), dtype=tf.int32)\n",
    "        }\n",
    "        _ = model(dummy_input)\n",
    "        print(\"Initialized model architecture\")\n",
    "            \n",
    "        # 4. Load weights\n",
    "        weights_path = os.path.join(model_dir, f\"enhanced_distilbert_epoch{epoch}_weights\")\n",
    "        if not os.path.exists(weights_path + '.index'):\n",
    "            raise FileNotFoundError(f\"Model weights not found at: {weights_path}\")\n",
    "            \n",
    "        model.load_weights(weights_path)\n",
    "        print(\"Loaded model weights successfully\")\n",
    "            \n",
    "        # 5. Compile model\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=Config.LEARNING_RATE),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        print(\"Model compiled successfully\")\n",
    "            \n",
    "        print(\"\\nModel loaded successfully!\")\n",
    "        print(f\"Original training epochs: {model_info['epoch']}\")\n",
    "        print(f\"Final validation accuracy: {model_info['history']['val_accuracy'][-1]:.4f}\")\n",
    "            \n",
    "        return model, model_info['history']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError loading model: {str(e)}\")\n",
    "        print(\"Load location attempted: \", model_dir)\n",
    "        raise\n",
    "\n",
    "# Then in another cell, load the model:\n",
    "epoch = 10\n",
    "loaded_model, training_history = load_saved_model(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb90140f-2cea-4b08-80df-88386c855bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. loading the previously saved model:\n",
    "epoch = 10  \n",
    "loaded_model, training_history = load_saved_model(epoch)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fbb9d84f-be2a-42e0-981e-bbe01e7690f3",
   "metadata": {},
   "source": [
    "4: Training Visualization\n",
    "\n",
    "This cell creates visualizations of the model's training metrics:\n",
    "- Initializes the visualization tool\n",
    "- Creates plots showing:\n",
    "    - Training and validation losses\n",
    "    - Accuracy metrics\n",
    "    - Other performance indicators\n",
    "\n",
    "This helps in understanding how the model learned over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6105dabd-93b6-4918-8e71-267938b6bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create components\n",
    "\n",
    "from models.sentiment_model import ModelTrainer\n",
    "model = loaded_model\n",
    "trainer = ModelTrainer(model=model)\n",
    "evaluator = ModelEvaluator(model, trainer)\n",
    "\n",
    "# Run evaluation\n",
    "eval_results = evaluator.evaluate_model(analyzer.test_texts, analyzer.test_labels)\n",
    "evaluator.visualize_performance(eval_results, training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e54a1d-dfa1-4b39-ad83-3be9bec72a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "from main import SentimentAnalyzer# Create tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Initialize analyzer with both model and tokenizer\n",
    "analyzer = SentimentAnalyzer()\n",
    "analyzer.model = loaded_model\n",
    "analyzer.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7d9fa9-7ba0-4537-860c-c4dfbdb25a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sentiment_edge_cases(analyzer):\n",
    "   \"\"\"\n",
    "   Test sentiment analyzer with various edge cases organized by sentiment and linguistic pattern.\n",
    "   \n",
    "   Args:\n",
    "       analyzer: Initialized SentimentAnalyzer instance\n",
    "   \"\"\"\n",
    "   test_cases = {\n",
    "       \"Positive with Negation\": [\n",
    "           (\"I can't deny that this place is amazing. Not a single thing wrong with the food or service!\", \"Double Negative -> Positive\"),\n",
    "           (\"Never had a bad experience here. The food isn't anything less than perfect.\", \"Negated Negative\"),\n",
    "           (\"Not once have I been disappointed by their service. The staff isn't unfriendly at all.\", \"Complex Negation\")\n",
    "       ],\n",
    "       \n",
    "       \"Positive with Sarcasm\": [\n",
    "           (\"Yeah right, like this restaurant could possibly get ANY better! *chef's kiss* Absolutely perfect!\", \"Exaggerated Praise\"),\n",
    "           (\"Oh sure, just RUIN my diet with your impossibly delicious desserts! How dare you be this good!\", \"Mock Complaint\"),\n",
    "           (\"Just what I needed - another restaurant to be obsessed with! üôÑ Now I'll have to keep coming back!\", \"Fake Annoyance\")\n",
    "       ],\n",
    "       \n",
    "       \"Positive with Multipolarity\": [\n",
    "           (\"The wait was long but honestly worth every minute. Amazing food and exceptional service!\", \"Contrast Resolution\"),\n",
    "           (\"Small portions and pricey, but the taste makes up for everything. Will definitely return!\", \"Trade-off Acceptance\"),\n",
    "           (\"Noisy atmosphere but incredible food and the best service I've had in years.\", \"Mixed with Positive Dominance\")\n",
    "       ],\n",
    "       \n",
    "       \"Negative with Negation\": [\n",
    "           (\"The food isn't good at all. Not worth the price and I won't be returning.\", \"Direct Negative\"),\n",
    "           (\"I couldn't find anything special about this place. The service wasn't even close to acceptable.\", \"Compound Negative\"),\n",
    "           (\"Not once did they get our order right. The manager wasn't helpful either.\", \"Sequential Negative\")\n",
    "       ],\n",
    "       \n",
    "       \"Negative with Sarcasm\": [\n",
    "           (\"Oh fantastic, another overpriced meal with cold food. Just what I was hoping for! üôÑ\", \"Mock Enthusiasm\"),\n",
    "           (\"Wow, amazing how they consistently manage to mess up a simple order. Such talent! üòí\", \"Ironic Praise\"),\n",
    "           (\"Five stars for teaching me the true meaning of patience! Best 2-hour wait ever! üôÉ\", \"Exaggerated Compliment\")\n",
    "       ],\n",
    "       \n",
    "       \"Negative with Multipolarity\": [\n",
    "           (\"Great location but terrible food and even worse service. Definitely not returning.\", \"Location vs Experience\"),\n",
    "           (\"Beautiful decor, shame about the rude staff and inedible food.\", \"Aesthetics vs Function\"),\n",
    "           (\"Nice ambiance but overpriced food and disappointing service ruined the experience.\", \"Environment vs Service\")\n",
    "       ],\n",
    "       \n",
    "       \"Neutral with Negation\": [\n",
    "           (\"The food isn't amazing but isn't terrible either. Just an average experience.\", \"Balanced Negation\"),\n",
    "           (\"Not the best, not the worst. Wouldn't go out of my way to return.\", \"Double Neutral Negation\"),\n",
    "           (\"Can't say it was great, can't say it was bad. Just okay.\", \"Negated Extremes\")\n",
    "       ],\n",
    "       \n",
    "       \"Neutral with Sarcasm\": [\n",
    "           (\"Well, that was... an experience. I guess that's one way to run a restaurant! ü§î\", \"Ambiguous Evaluation\"),\n",
    "           (\"'Interesting' take on Italian food. Very... unique interpretation! üòè\", \"Noncommittal Sarcasm\"),\n",
    "           (\"Such a... memorable experience. Definitely different from what I expected! ü´§\", \"Understated Sarcasm\")\n",
    "       ],\n",
    "       \n",
    "       \"Neutral with Multipolarity\": [\n",
    "           (\"Good food but slow service. Bad parking but nice location. Evens out I guess.\", \"Balanced Trade-offs\"),\n",
    "           (\"Some dishes were great, others terrible. Service varied. Hard to form an opinion.\", \"Mixed Experience\"),\n",
    "           (\"Excellent appetizers, mediocre mains, poor desserts. Averages out to okay.\", \"Quality Variation\")\n",
    "       ]\n",
    "   }\n",
    "   \n",
    "   for category, cases in test_cases.items():\n",
    "       print(f\"\\n=== Testing {category} ===\\n\")\n",
    "       for text, case_type in cases:\n",
    "           prediction = analyzer.predict(text)\n",
    "           print(f\"Case Type: {case_type}\")\n",
    "           print(f\"Text: {text}\")\n",
    "           print(f\"Prediction: {prediction}\")\n",
    "           print()\n",
    "\n",
    "# Usage\n",
    "test_sentiment_edge_cases(analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d4488d-753d-4246-938f-fed8b70723e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
