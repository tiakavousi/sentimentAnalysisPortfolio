{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e90fc61-d654-4e77-b9d5-642b04861490",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "## key objectives:\n",
    "- Loading a pre-trained sentiment analysis model\n",
    "- Validating the model's functionality\n",
    "- Analyzing training performance through visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413858d9-a5f5-4033-92ac-1ab322f0f007",
   "metadata": {},
   "source": [
    "# Imports\n",
    "This code imports necessary libraries and modules for setting up the sentiment analysis project, including the setup for importing local project files, managing paths, and preparing for model training and evaluation. Here's an explanation of each part:\n",
    "\n",
    "1. **Library Imports:**\n",
    "   - `os` and `sys`: Used for interacting with the operating system, including setting paths and changing directories.\n",
    "   - `json`: Imports JSON parsing functionalities, which could be used for handling configuration or data.\n",
    "   - `tensorflow`: TensorFlow is used for deep learning, including training and evaluating models.\n",
    "   - `DistilBertTokenizer` from `transformers`: Imports the tokenizer for DistilBERT, a transformer model optimized for text-based tasks like sentiment analysis.\n",
    "   - `numpy`: Provides support for numerical operations, often used for array handling.\n",
    "   - `matplotlib.pyplot` and `seaborn`: Used for plotting graphs and visualizations (e.g., to visualize model performance).\n",
    "   - `defaultdict` from `collections`: A dictionary subclass that provides a default value for missing keys.\n",
    "\n",
    "2. **Project Path Setup:**\n",
    "   - `project_root`: Specifies the root directory of the project.\n",
    "   - `sys.path.insert(0, project_root)`: Adds the root directory to the Python module search path to allow importing local project modules.\n",
    "   - `os.chdir('../')`: Changes the current working directory to the parent directory.\n",
    "\n",
    "3. **Imports from Local Modules:**\n",
    "   - `EnhancedDistilBertForSentiment`, `ModelTrainer`, and other classes are imported from local modules, which are presumably implemented to handle sentiment analysis models, training, evaluation, and persistence.\n",
    "   - `Config`: Likely a configuration object for model parameters.\n",
    "   - `SentimentAnalyzer`: Likely the main class for performing sentiment analysis.\n",
    "   - `ModelPersistence`: A class for saving and loading trained models.\n",
    "   - `ModelEvaluator`: A class used to evaluate model performance.\n",
    "   - `DataProcessor`: A class to handle preprocessing and data management.\n",
    "\n",
    "4. **Path Setup for Models:**\n",
    "   - `project_path`: Defines the path to the project's directory.\n",
    "   - `model_path`: Constructs the path to a specific saved model version (`model_v2.0.0_epoch6`), which will be used for inference or evaluation.\n",
    "\n",
    "This cell primarily sets up the environment, imports necessary libraries, and configures paths for the sentiment analysis project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089e0e04-8ba1-4ca7-b79e-ff888b32498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from transformers import DistilBertTokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "project_root = '/Users/tayebekavousi/Desktop/sentimentAnalysisPortfolio'\n",
    "sys.path.insert(0, project_root)\n",
    "os.chdir('../')\n",
    "from models.sentiment_model import EnhancedDistilBertForSentiment, ModelTrainer\n",
    "from config.model_config import Config\n",
    "from main import SentimentAnalyzer\n",
    "from models.modelPersistence import ModelPersistence\n",
    "from utils.modelEvaluator import ModelEvaluator\n",
    "from data.data_processing import DataProcessor\n",
    "\n",
    "# Set paths\n",
    "project_path = \"/Users/tayebekavousi/Desktop/sentimentAnalysisPortfolio\"\n",
    "model_path = os.path.join(project_path, \"saved_models/model_v2.0.0_epoch6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4094c3d4-7a50-431f-b9d9-422702d53b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EnhancedDistilBertForSentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668457f2-b47d-4653-a3cb-ae15e120d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new model with the same architecture\n",
    "print(\"\\nInitializing model architecture...\")\n",
    "# Create a dummy input to build the model\n",
    "dummy_input = {\n",
    "    'input_ids': tf.zeros((1, Config.MAX_LENGTH), dtype=tf.int32),\n",
    "    'attention_mask': tf.zeros((1, Config.MAX_LENGTH), dtype=tf.int32)\n",
    "}\n",
    "_ = model(dummy_input)  # Build the model\n",
    "    \n",
    "# Load saved weights\n",
    "print(\"\\nLoading model weights...\")\n",
    "model.load_weights(os.path.join(model_path, \"full_model\", \"variables\", \"variables\"))\n",
    "\n",
    "# Load tokenizer\n",
    "print(\"\\nLoading tokenizer...\")\n",
    "loaded_tokenizer = DistilBertTokenizer.from_pretrained(os.path.join(model_path, \"tokenizer\"))\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = SentimentAnalyzer(model=model)\n",
    "analyzer.tokenizer = loaded_tokenizer\n",
    "analyzer.trainer = ModelTrainer(model, loaded_tokenizer)\n",
    "analyzer.data_processor = DataProcessor()\n",
    "\n",
    "# Test the loaded model\n",
    "test_texts = [\n",
    "    \"The food was absolutely amazing! Best restaurant experience ever!\",\n",
    "    \"Service was terrible and the food was cold.\",\n",
    "    \"It was okay, nothing special but nothing terrible either.\"\n",
    "]\n",
    "\n",
    "print(\"\\nTesting model with sample reviews:\")\n",
    "for text in test_texts:\n",
    "    result = analyzer.predict(text)\n",
    "    print(f\"\\nInput: {text}\")\n",
    "    print(\"Prediction:\", json.dumps(result, indent=2))\n",
    "\n",
    "print(\"\\nModel loaded successfully! Ready for predictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70215e59-5007-4187-90cf-31ad119a255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the  evaluator\n",
    "evaluator = ModelEvaluator(model, analyzer.trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1dfdf6-4576-4956-b5c6-e89e9e4b51ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data first\n",
    "analyzer.process_data()\n",
    "\n",
    "# Now get the test set\n",
    "test_texts = analyzer.processed_data['dataframes']['test']['processed_text'].to_numpy()\n",
    "test_labels = {'sentiment': analyzer.processed_data['model_inputs'][5]['sentiment']}\n",
    "\n",
    "# Evaluate model on test set\n",
    "test_metrics = evaluator.evaluate_model(test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce821ab1-158d-4418-b879-4caf943bbbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training history from config\n",
    "with open(os.path.join(model_path, \"config.json\"), 'r') as f:\n",
    "    training_history = json.load(f)['performance']\n",
    "\n",
    "# Create and display visualization\n",
    "fig = visualize_results(training_history, test_metrics, evaluator.label_map)\n",
    "plt.show()\n",
    "\n",
    "# Print additional summary metrics\n",
    "print(\"\\nTest Set Performance Summary:\")\n",
    "print(f\"Overall Accuracy: {test_metrics['overall_accuracy']:.3f}\")\n",
    "print(\"\\nPer-class Performance:\")\n",
    "for label, metrics in test_metrics['class_metrics'].items():\n",
    "    print(f\"\\n{label}:\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.3f}\")\n",
    "    print(f\"Support: {metrics['support']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a00a4-c465-400c-a537-5e38ecc343c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.performance_visualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9ebb3b-a2eb-4c30-95e0-a306c0c5b9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Testing Edge Cases ===\")\n",
    "edge_case_results = evaluator.test_sentiment_edge_cases(analyzer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
