{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.7\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')  # Moving up one directory to the root\n",
    "!python --version\n",
    "os.environ['WRAPT_DISABLE_EXTENSIONS'] = 'true'\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 14:43:31.737035: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from main import SentimentAnalyzer\n",
    "from models.sentiment_model import EnhancedDistilBertForSentiment, ModelTrainer\n",
    "from config.model_config import ModelConfig\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing Examples:\n",
      "\n",
      "Original: Great service and amazing food!\n",
      "Processed: Great service and amazing food!\n",
      "\n",
      "Original: Terrible experience, would not recommend.\n",
      "Processed: Terrible experience, would not_NEG recommend.\n",
      "\n",
      "Original: The food was okay, but the service could be better.\n",
      "Processed: The food was okay, but the service could be better.\n",
      "\n",
      "Original: Yeah right, like that's going to work...\n",
      "Processed: Yeah right, like that is going to work ELLIPSIS  _SARC_yeah right\n",
      "\n",
      "Original: Thanks a lot... now everything is broken 🙄\n",
      "Processed: Thanks a lot ELLIPSIS  now everything is broken 🙄 _SARC_thanks a lot (contextual)\n",
      "\n",
      "Original: Obviously this is the best restaurant ever...\n",
      "Processed: Obviously this is the best restaurant ever ELLIPSIS \n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Initialize analyzer\n",
    "analyzer = SentimentAnalyzer()\n",
    "\n",
    "# Process and show preprocessing examples\n",
    "train_texts, val_texts, train_labels, val_labels = analyzer.process_data()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Configuration:\n",
      "BERT Model: distilbert-base-uncased\n",
      "Learning Rate: 1e-05\n",
      "Batch Size: 32\n",
      "Max Length: 200\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create the analyzer instance first\n",
    "analyzer = SentimentAnalyzer()\n",
    "\n",
    "# Then initialize the model\n",
    "analyzer.initialize_model()\n",
    "analyzer.initialize_model()\n",
    "\n",
    "# Show model configuration\n",
    "print(\"Model Configuration:\")\n",
    "print(f\"BERT Model: {ModelConfig.BERT_MODEL}\")\n",
    "print(f\"Learning Rate: {ModelConfig.LEARNING_RATE}\")\n",
    "print(f\"Batch Size: {ModelConfig.BATCH_SIZE}\")\n",
    "print(f\"Max Length: {ModelConfig.MAX_LENGTH}\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"enhanced_distil_bert_for_sentiment_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tf_distil_bert_model_1 (TF  multiple                  66362880  \n",
      " DistilBertModel)                                                \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  multiple                  1154400   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  30048     \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  30048     \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  30048     \n",
      "                                                                 \n",
      " dense_8 (Dense)             multiple                  31040     \n",
      "                                                                 \n",
      " dense_9 (Dense)             multiple                  51360     \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " sentiment (Dense)           multiple                  483       \n",
      "                                                                 \n",
      " sarcasm (Dense)             multiple                  161       \n",
      "                                                                 \n",
      " negation (Dense)            multiple                  161       \n",
      "                                                                 \n",
      " polarity (Dense)            multiple                  161       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67690790 (258.22 MB)\n",
      "Trainable params: 67690790 (258.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create a dummy input to build the model\n",
    "dummy_input = analyzer.tokenizer(\n",
    "    \"This is a dummy text\", \n",
    "    return_tensors='tf',\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=ModelConfig.MAX_LENGTH\n",
    ")\n",
    "\n",
    "# Build the model by passing dummy input\n",
    "_ = analyzer.model(dummy_input)\n",
    "analyzer.model.summary()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 91/169 [===============>..............] - ETA: 1:02:40 - loss: 1.4326 - negation_loss: 0.2959 - polarity_loss: 0.1679 - sarcasm_loss: 0.2713 - sentiment_loss: 1.0986 - negation_accuracy: 0.9856 - polarity_mae: 0.3291 - sarcasm_accuracy: 0.9959 - sentiment_accuracy: 0.3743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Traceback (most recent call last):\n",
      "'zmq.backend.cython.message.Frame.__dealloc__'\n",
      "Traceback (most recent call last):\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/xc/qkmv0r456dn4gsy6rfgnpns80000gn/T/ipykernel_47201/372926428.py\", line 3, in <module>\n",
      "    history = analyzer.train()\n",
      "              ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tayebekavousi/Desktop/sentimentAnalysisPortfolio/main.py\", line 95, in train\n",
      "    return self.trainer.train(train_dataset, val_dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tayebekavousi/Desktop/sentimentAnalysisPortfolio/models/sentiment_model.py\", line 114, in train\n",
      "    history = self.model.fit(\n",
      "              ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1804, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 833, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 869, in _call\n",
      "    return tracing_compilation.call_function(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
      "    return function._call_flat(  # pylint: disable=protected-access\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1322, in _call_flat\n",
      "    return self._inference_function.call_preflattened(args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
      "    flat_outputs = self.call_flat(*args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
      "    outputs = self._bound_context.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/context.py\", line 1500, in call_function\n",
      "    outputs = execute.execute(\n",
      "              ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py\", line 317, in executing\n",
      "    args = executing_cache[key]\n",
      "           ~~~~~~~~~~~~~~~^^^^^\n",
      "KeyError: (<code object fit at 0x7ff0d4e1c600, file \"/opt/anaconda3/lib/python3.12/site-packages/tf_keras/src/engine/training.py\", line 1452>, 140672340444672, 1460)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# training visualization\u001b[39;00m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[0;32m~/Desktop/sentimentAnalysisPortfolio/main.py:95\u001b[0m, in \u001b[0;36mSentimentAnalyzer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprepare_dataset(val_texts, val_labels)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Train using ModelTrainer\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain(train_dataset, val_dataset)\n",
      "File \u001b[0;32m~/Desktop/sentimentAnalysisPortfolio/models/sentiment_model.py:114\u001b[0m, in \u001b[0;36mModelTrainer.train\u001b[0;34m(self, train_dataset, val_dataset)\u001b[0m\n\u001b[1;32m    111\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m strategy\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m--> 114\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    115\u001b[0m         train_dataset,\n\u001b[1;32m    116\u001b[0m         validation_data\u001b[38;5;241m=\u001b[39mval_dataset,\n\u001b[1;32m    117\u001b[0m         epochs\u001b[38;5;241m=\u001b[39mModelConfig\u001b[38;5;241m.\u001b[39mEPOCHS,\n\u001b[1;32m    118\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_callbacks()\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tf_keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tf_keras/src/engine/training.py:1804\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1798\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1801\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1802\u001b[0m ):\n\u001b[1;32m   1803\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1804\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1806\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    870\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[1;32m    871\u001b[0m   )\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "history = analyzer.train()\n",
    "\n",
    "# training visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "# Loss plots\n",
    "plt.subplot(1, 3, 1)\n",
    "for metric in ['sentiment_loss', 'sarcasm_loss', 'negation_loss', 'polarity_loss']:\n",
    "    if metric in history.history:\n",
    "        plt.plot(history.history[metric], label=metric)\n",
    "plt.title('Model Losses')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plots\n",
    "plt.subplot(1, 3, 2)\n",
    "for metric in ['sentiment_accuracy', 'sarcasm_accuracy', 'negation_accuracy']:\n",
    "    if metric in history.history:\n",
    "        plt.plot(history.history[metric], label=metric)\n",
    "plt.title('Model Accuracies')\n",
    "plt.legend()\n",
    "\n",
    "# MAE for polarity\n",
    "plt.subplot(1, 3, 3)\n",
    "if 'polarity_mae' in history.history:\n",
    "    plt.plot(history.history['polarity_mae'], label='polarity_mae')\n",
    "plt.title('Polarity MAE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = {\n",
    "   'positive': [\n",
    "       \"The service was exceptional! The staff went above and beyond, the food was perfectly cooked, and the ambiance was wonderful. Everything from appetizers to dessert was a delight. Will definitely return!\",\n",
    "       \"What an amazing dining experience! Every dish was beautifully presented, flavors were incredible, and the chef's special menu was innovative. Service was impeccable and attentive.\",\n",
    "       \"First time here and absolutely loved it! The seafood pasta was fresh and flavorful, wine selection was excellent, and the outdoor seating area is gorgeous. Worth every penny!\",\n",
    "       \"Best restaurant in the city! Incredible selection of dishes, outstanding cocktails, and the desserts are to die for. The atmosphere is perfect for both casual dining and special occasions.\",\n",
    "       \"Phenomenal experience from start to finish! The steak was cooked to perfection, sides were creative and delicious, and the service was top-notch. Can't wait to come back!\"\n",
    "   ],\n",
    "   'negative': [\n",
    "       \"Terrible experience. Food was cold, service was slow, and prices were ridiculous for what we got. The waiter was rude and unattentive. Definitely won't be coming back to this place.\",\n",
    "       \"Disappointing dinner. Everything was bland, overcooked, and overpriced. Waited 45 minutes for our main course and the restaurant wasn't even busy. Save your money and go elsewhere.\",\n",
    "       \"Worst dining experience ever! The food was inedible, the place was dirty, and we found a hair in our salad. Management didn't even care when we complained. Avoid at all costs!\",\n",
    "       \"Complete waste of money. The portions were tiny, food was mediocre at best, and the service was awful. The place was too noisy and the tables were uncomfortably close together.\",\n",
    "       \"Extremely disappointing. Food arrived cold, drinks were watered down, and the place was unclean. Staff seemed untrained and disinterested. Definitely not worth the high prices.\"\n",
    "   ],\n",
    "   'neutral': [\n",
    "       \"The food was okay, nothing special. Service was standard, and prices were what you'd expect. The place was clean but basic. Might return if in the area, but wouldn't go out of my way.\",\n",
    "       \"Average experience overall. Some dishes were good, others were mediocre. Service was acceptable but not memorable. The atmosphere was typical for this type of restaurant.\",\n",
    "       \"Had dinner here last night. Food came on time, taste was decent. Prices are standard for the area. The place is what you'd expect from a casual dining restaurant.\",\n",
    "       \"Regular restaurant experience. The menu has typical options, service was neither good nor bad. Ambiance is basic. It's fine for a quick meal but don't expect anything extraordinary.\",\n",
    "       \"Standard dining experience. Food was edible but not remarkable. Wait staff were polite but busy. Prices are average for what you get. It's an okay option if you're in the neighborhood.\"\n",
    "   ],\n",
    "   'sarcasm': [\n",
    "       \"Oh yeah, waiting an hour for cold food is EXACTLY what I wanted for my birthday. The rude service really made the experience special. Just perfect! 🙄\",\n",
    "       \"Wow, thanks SO MUCH for the amazing experience of watching other tables get served while we waited. The cold food was definitely worth the two-hour wait! 😒\",\n",
    "       \"Sure, charging $50 for microwaved pasta is totally reasonable! And the waiter's attitude? Cherry on top! Obviously the best restaurant ever... 🙄\",\n",
    "       \"Yeah right, this place is definitely deserving of its 'premium' status. Nothing says luxury like paper napkins and plastic cups. Simply magnificent... 😏\",\n",
    "       \"Just what I needed - overpriced, undercooked food with a side of attitude! The sticky tables really added to the 'authentic' experience. Thanks a lot! 🙄\"\n",
    "   ],\n",
    "   'negation': [\n",
    "       \"The food was not fresh at all. Service wasn't good either. The ambiance didn't match the prices, and the manager wouldn't address our concerns.\",\n",
    "       \"Cannot recommend this place. The menu isn't extensive, prices aren't reasonable, and the staff didn't seem to care about customer service at all.\",\n",
    "       \"The restaurant didn't meet our expectations. Food wasn't hot when served, flavors weren't balanced, and the waiter never checked on our table.\",\n",
    "       \"This place is not worth visiting. The food wasn't properly cooked, service wasn't professional, and the atmosphere wasn't pleasant at all.\",\n",
    "       \"The chef couldn't cook properly. The staff didn't know the menu, and the manager wouldn't accept any feedback. Never returning here.\"\n",
    "   ],\n",
    "   'multipolar': [\n",
    "       \"Great appetizers but terrible main courses. The service was excellent, yet the prices were outrageous. Beautiful decor but unbearably noisy.\",\n",
    "       \"The food was delicious but the service was awful. Love the atmosphere, however the cleanliness needs work. Amazing cocktails but terrible wine selection.\",\n",
    "       \"Fantastic starters but disappointing entrees. The staff was friendly but extremely slow. Beautiful venue but uncomfortable seating arrangements.\",\n",
    "       \"Excellent food quality but tiny portions. The bartender was amazing, yet the servers were rude. Love the concept but poor execution.\",\n",
    "       \"Perfect location but horrible parking. The food was tasty but overpriced. Friendly host but inattentive waiters. Mixed feelings about this place.\"\n",
    "   ],\n",
    "   'long_reviews': [\n",
    "       \"Had a truly memorable experience at this establishment last weekend. The atmosphere immediately draws you in with its perfect blend of modern and classic decor. Started with their signature appetizers - the calamari was perfectly crispy and the truffle fries were addictive. Main courses were even better; the sea bass was cooked to perfection and practically melted in the mouth. Wine pairing suggestions were spot-on. Service was attentive without being intrusive. The dessert menu was innovative - tried their deconstructed cheesecake which was a delightful surprise. Pricing was on the higher side but justified by the quality. Will definitely return!\",\n",
    "       \"After months of trying to get a reservation, our experience was unfortunately disappointing. While the ambiance was elegant with stunning city views, everything else fell short. Service was painfully slow and disorganized - waited 45 minutes between appetizers and main course. The food arrived lukewarm and wasn't worth the premium pricing. The wagyu steak was overcooked despite requesting medium-rare, and the seafood platter didn't taste fresh. When we raised these issues, the manager seemed indifferent. The cocktails were the only saving grace, but not enough to warrant a second visit. Save your money and try somewhere else.\",\n",
    "       \"The restaurant offers a standard dining experience with some hits and misses. Decor is contemporary but could use updating. The menu features typical Italian dishes - some executed well, others needing improvement. Service was adequate but not exceptional, and prices align with similar establishments in the area. The pasta dishes were cooked properly, though sauces lacked depth. Wine list is decent but not extensive. Seating is comfortable, noise level manageable. Parking can be challenging during peak hours. It's a safe choice for casual dining but doesn't stand out in any particular way.\",\n",
    "       \"Oh, what a 'delightful' evening! 🙄 Absolutely LOVED waiting 45 minutes past our reservation time, especially appreciated being squeezed into a tiny table right by the kitchen door. The waiter's complete lack of knowledge about the menu was simply CHARMING! And how thoughtful of them to serve us cold food at premium prices - such a unique dining concept! The manager's defensive attitude when we complained was the cherry on top of this 'exceptional' experience. But hey, at least the water glasses were full... when we could find someone to fill them. Just perfect for our anniversary celebration!\",\n",
    "       \"This restaurant perfectly embodies both excellence and disappointment. The appetizers were absolutely stunning - perfectly seasoned and beautifully presented. However, the main courses were a complete letdown with overcooked proteins and bland sauces. The sommelier was incredibly knowledgeable and helpful, but our server was inattentive and seemed disinterested. The venue itself is gorgeous with amazing waterfront views, yet the tables are uncomfortably close together. The dessert menu looked promising but the execution was inconsistent. Mixed feelings about recommending this place despite its potential.\"\n",
    "   ]\n",
    "}\n",
    "\n",
    "print(\"\\nComprehensive Sentiment Analysis:\")\n",
    "for category, cases in test_cases.items():\n",
    "    print(f\"\\n{category.upper()} CASES:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for text in cases:\n",
    "        results = analyzer.predict(text)\n",
    "        print(f\"\\nText: {text}\")\n",
    "        print(f\"Sentiment: {max(results['sentiment'].items(), key=lambda x: x[1])[0]}\")\n",
    "        print(f\"Sentiment Distribution: neg={results['sentiment']['negative']:.2f}, \"\n",
    "              f\"neu={results['sentiment']['neutral']:.2f}, \"\n",
    "              f\"pos={results['sentiment']['positive']:.2f}\")\n",
    "        print(f\"Sarcasm: {results['sarcasm']['detected']}\")\n",
    "        print(f\"Negation: {results['negation']['detected']}\")\n",
    "        print(f\"Multipolarity Score: {results['multipolarity']['score']:.2f}\")\n",
    "        print(f\"Is Multipolar: {results['multipolarity']['is_multipolar']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
